1. プロジェクト情報
項目	内容
プロジェクトID	polar-xxxxxx-xxxxxx
デフォルトリージョン	Cloud Run / Cloud Scheduler で使用する場合に必要（例: asia-northeast1）
デフォルトゾーン	VM や Compute Engine 使用時に必要
2. サービスアカウント
項目	内容
使用するサービスアカウント	polar-xxxxxx@appspot.gserviceaccount.com
IAM 権限	- roles/storage.objectAdmin（Cloud Storage 操作用）
- roles/editor（その他基本操作）
メモ	今後追加で Cloud Run 用にカスタムサービスアカウントを作る場合は名前と権限を記録
3. Cloud Storage
項目	内容
バケット名	データ格納先のバケット名を記録
アクセス権限	上記サービスアカウントがオブジェクト操作可能か確認済み
ファイル構成	CSV ファイル、スクリプトに必要なデータなどの整理
4. Cloud Run / Docker
項目	内容
サービス名	Cloud Run サービス名を記録
コンテナイメージ	Artifact Registry に push したイメージのパス
asia-northeast1-docker.pkg.dev/<PROJECT_ID>/<REPO>/<IMAGE>:<TAG>
CPU/メモリ	定期実行に必要なリソース（例: 1 CPU, 512MB メモリ）
環境変数	スクリプト内で参照する変数（例: PROJECT_ID, BUCKET_NAME）
5. Cloud Scheduler
項目	内容
ジョブ名	記録しておくと再設定や編集が簡単
実行間隔	例: every 30 minutes
対象	Cloud Run サービス URL（HTTP トリガー）
認証方法	サービスアカウント経由で呼び出す場合は対象サービスアカウントを指定
6. スクリプト情報
項目	内容
Python スクリプト名	例: process_csv.py
ライブラリ	pandas, playwright など
venv/依存	Docker イメージに含めるパッケージ一覧
CSV 入力 / 出力	csv1.csv → csv2.csv のフロー、列・行の扱いのルール
7. ログ・デバッグ
項目	内容
Cloud Run ログ	gcloud logs read で確認可能
Cloud Scheduler ログ	実行結果、HTTP レスポンスを確認
ローカルテスト用	python process_csv.py で動作確認、Docker コンテナ内での実行確認

💡 メモのポイント

サービスアカウントやイメージ名、バケット名などは一貫して記録しておく

Cloud Scheduler と Cloud Run を紐づける際は、ジョブ名とサービス URL を忘れない

定期実行前にローカルで Docker コンテナを動かしてテストしておくと安全

必要であれば、これを 1枚のメモ表 にまとめて後日すぐ見られる形にも作れます。
作っておきますか？

Microsoft Windows [Version 10.0.19045.6216]
(c) Microsoft Corporation. All rights reserved.

C:\Users\ユーザー\OneDrive\Desktop\pythonForKeiba\定期実行行き\getDevAndPop(Dockerfile)>gcloud artifacts repositories delete REPO_NAME --location=asia-northeast1 --quiet
ERROR: (gcloud.artifacts.repositories.delete) NOT_FOUND: Requested entity was not found. This command is authenticated as xxxxxx@gmail.com which is the active account specified by the [core/account] property.

C:\Users\ユーザー\OneDrive\Desktop\pythonForKeiba\定期実行行き\getDevAndPop(Dockerfile)>gcloud config set project polar-xxxxxx
Updated property [core/project].


Updates are available for some Google Cloud CLI components.  To install them,
please run:
  $ gcloud components update


C:\Users\ユーザー\OneDrive\Desktop\pythonForKeiba\定期実行行き\getDevAndPop(Dockerfile)>gcloud components update
Beginning update. This process may take several minutes.

Restarting command:
  $ gcloud components update


C:\Users\ユーザー\OneDrive\Desktop\pythonForKeiba\定期実行行き\getDevAndPop(Dockerfile)>gcloud components update
Beginning update. This process may take several minutes.

All components are up to date.

C:\Users\ユーザー\OneDrive\Desktop\pythonForKeiba\定期実行行き\getDevAndPop(Dockerfile)>gcloud config set project polar-xxxxxx
Updated property [core/project].

C:\Users\ユーザー\OneDrive\Desktop\pythonForKeiba\定期実行行き\getDevAndPop(Dockerfile)>gcloud services enable run.googleapis.com artifactregistry.googleapis.com pubsub.googleapis.com cloudscheduler.googleapis.com
Operation "xxxxxx" finished successfully.

C:\Users\ユーザー\OneDrive\Desktop\pythonForKeiba\定期実行行き\getDevAndPop(Dockerfile)>gcloud artifacts repositories create my-docker-repo --repository-format=docker --location=asia-northeast1 --description="Docker repo for Cloud Run service"
Create request issued for: [my-docker-repo]
Waiting for operation [projects/polar-xxxxxx/locations/asia-northeast1/operationsxxxxxx
5082048] to complete...done.
Created repository [my-docker-repo].

C:\Users\ユーザー\OneDrive\Desktop\pythonForKeiba\定期実行行き\getDevAndPop(Dockerfile)>gcloud builds submit --tag asia-northeast1-docker.pkg.dev/polar-xxxxxx/my-docker-repo/my-service
Creating temporary archive of 3 file(s) totalling 3.8 KiB before compression.
Uploading tarball of [.] to [xxxxxx.tgz]
Created [https://cloudbuild.googleapis.com/v1/projects/polar-xxxxxx/locations/global/builds/xxxxxx].
Logs are available at [ https://console.cloud.google.com/cloud-build/builds/xxxxxx ].
Waiting for build to complete. Polling interval: 1 second(s).
------------------------------------------------- REMOTE BUILD OUTPUT --------------------------------------------------starting build xxxxxxx

